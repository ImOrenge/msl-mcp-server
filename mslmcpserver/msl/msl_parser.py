"""
MSL (Macro Scripting Language) íŒŒì„œ (Parser)
Lexerê°€ ìƒì„±í•œ í† í°ì„ ë°›ì•„ì„œ AST(Abstract Syntax Tree)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

íŒŒì‹± ìš°ì„ ìˆœìœ„ (ë†’ì€ ìˆœ):
1. ê·¸ë£¹í™”: ( )
2. í† ê¸€: ~
3. ë°˜ë³µ: *
4. ì—°ì†ì…ë ¥: &
5. í™€ë“œì—°ê²°: >
6. ë³‘ë ¬ì‹¤í–‰: |
7. ë™ì‹œì‹¤í–‰: +
8. ìˆœì°¨ì‹¤í–‰: ,

íƒ€ì´ë° ì œì–´:
- (ìˆ«ì): ì§€ì—° ì‹œê°„
- [ìˆ«ì]: í™€ë“œ ì‹œê°„
- {ìˆ«ì}: ë°˜ë³µ ê°„ê²©
- <ìˆ«ì>: í˜ì´ë“œ ì‹œê°„
"""

import re
from typing import List, Optional, Union, Dict
from .msl_lexer import MSLLexer, Token, TokenType
from .msl_ast import *


class ParseError(Exception):
    """MSL íŒŒì‹± ì˜¤ë¥˜ - êµ¬ë¬¸ ë¶„ì„ ì¤‘ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤"""
    
    def __init__(self, message: str, token: Optional[Token] = None):
        """
        íŒŒì‹± ì˜¤ë¥˜ ì´ˆê¸°í™”
        
        Args:
            message (str): ì˜¤ë¥˜ ë©”ì‹œì§€
            token (Token, optional): ì˜¤ë¥˜ê°€ ë°œìƒí•œ í† í°
        """
        self.message = message
        self.token = token
        
        if token:
            super().__init__(f"Line {token.line}, Column {token.column}: {message}")
        else:
            super().__init__(message)


class MSLParser:
    """MSL íŒŒì„œ - í† í°ì„ êµ¬ë¬¸ íŠ¸ë¦¬ë¡œ ë³€í™˜í•˜ëŠ” í•µì‹¬ ì»´í¬ë„ŒíŠ¸"""
    
    def __init__(self):
        """MSL Parser ì´ˆê¸°í™”"""
        self.tokens: List[Token] = []
        self.current_position = 0
        self.current_token: Optional[Token] = None
        
        # ë³€ìˆ˜ ì €ì¥ì†Œ (íŒŒì‹± ì‹œì ì—ëŠ” ì²´í¬ë§Œ)
        self.variables: Dict[str, MSLNode] = {}
    
    def parse(self, text: str) -> MSLNode:
        """
        MSL ìŠ¤í¬ë¦½íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ ASTë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            text (str): MSL ìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸
            
        Returns:
            MSLNode: ë£¨íŠ¸ AST ë…¸ë“œ
            
        Raises:
            ParseError: íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ ì‹œ
            
        Example:
            >>> parser = MSLParser()
            >>> ast = parser.parse("W(500),A")
            >>> # SequentialNode with KeyNode and DelayNode
        """
        # 1. í† í°í™”
        lexer = MSLLexer()
        self.tokens = lexer.tokenize(text)
        
        # 2. ì£¼ì„ ë° ê³µë°± ì œê±° - íŒŒì‹±ì— ë¶ˆí•„ìš”í•œ í† í° ì œê±°
        self.tokens = [token for token in self.tokens 
                      if token.type not in [TokenType.COMMENT, TokenType.WHITESPACE]]
        
        # 3. í† í° ìœ íš¨ì„± ê²€ì‚¬
        errors = lexer.validate_tokens(self.tokens)
        if errors:
            raise ParseError(f"í† í° ì˜¤ë¥˜: {', '.join(errors)}")
        
        # 4. íŒŒì‹± ì´ˆê¸°í™”
        self.current_position = 0
        self.current_token = self.tokens[0] if self.tokens else None
        
        # 5. íŒŒì‹± ì‹œì‘
        if not self.tokens or self.tokens[0].type == TokenType.EOF:
            raise ParseError("ë¹ˆ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤")
        
        try:
            ast = self.parse_expression()
            
            # 6. ëª¨ë“  í† í°ì´ ì†Œë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if self.current_token and self.current_token.type != TokenType.EOF:
                raise ParseError(f"ì˜ˆìƒì¹˜ ëª»í•œ í† í°: {self.current_token.value}", self.current_token)
            
            return ast
            
        except IndexError:
            raise ParseError("ì˜ˆìƒì¹˜ ëª»í•œ ìŠ¤í¬ë¦½íŠ¸ ë")
    
    def advance(self) -> Optional[Token]:
        """ë‹¤ìŒ í† í°ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤"""
        if self.current_position < len(self.tokens) - 1:
            self.current_position += 1
            self.current_token = self.tokens[self.current_position]
        else:
            self.current_token = None
        return self.current_token
    
    def peek(self, offset: int = 1) -> Optional[Token]:
        """ì•ìœ¼ë¡œ offsetë§Œí¼ ë–¨ì–´ì§„ í† í° í™•ì¸ (ì´ë™í•˜ì§€ ì•ŠìŒ)"""
        pos = self.current_position + offset
        if 0 <= pos < len(self.tokens):
            return self.tokens[pos]
        return None
    
    def expect(self, token_type: TokenType) -> Token:
        """í˜„ì¬ í† í°ì´ ì˜ˆìƒ íƒ€ì…ì¸ì§€ í™•ì¸í•˜ê³  ë‹¤ìŒìœ¼ë¡œ ì´ë™"""
        if not self.current_token or self.current_token.type != token_type:
            expected = token_type.value
            actual = self.current_token.value if self.current_token else "EOF"
            raise ParseError(f"ì˜ˆìƒ: {expected}, ì‹¤ì œ: {actual}", self.current_token)
        
        token = self.current_token
        self.advance()
        return token
    
    def match(self, *token_types: TokenType) -> bool:
        """í˜„ì¬ í† í°ì´ ì£¼ì–´ì§„ íƒ€ì…ë“¤ ì¤‘ í•˜ë‚˜ì¸ì§€ í™•ì¸"""
        if not self.current_token:
            return False
        return self.current_token.type in token_types
    
    def parse_expression(self) -> MSLNode:
        """í‘œí˜„ì‹ íŒŒì‹± (ìµœìƒìœ„ ë ˆë²¨) - ìˆœì°¨ ì‹¤í–‰ë¶€í„° ì‹œì‘"""
        return self.parse_sequential()
    
    def parse_sequential(self) -> MSLNode:
        """ìˆœì°¨ ì‹¤í–‰ íŒŒì‹± (ê°€ì¥ ë‚®ì€ ìš°ì„ ìˆœìœ„: ,) - W,A,S,D"""
        left = self.parse_simultaneous()
        
        if self.match(TokenType.SEQUENTIAL):
            sequential_node = SequentialNode(self._get_position())
            sequential_node.add_child(left)
            
            while self.match(TokenType.SEQUENTIAL):
                self.advance()  # , ì†Œë¹„
                right = self.parse_simultaneous()
                sequential_node.add_child(right)
            
            return sequential_node
        
        return left
    
    def parse_simultaneous(self) -> MSLNode:
        """ë™ì‹œ ì‹¤í–‰ íŒŒì‹± (+) - Ctrl+C"""
        left = self.parse_parallel()
        
        if self.match(TokenType.SIMULTANEOUS):
            simultaneous_node = SimultaneousNode(self._get_position())
            simultaneous_node.add_child(left)
            
            while self.match(TokenType.SIMULTANEOUS):
                self.advance()  # + ì†Œë¹„
                right = self.parse_parallel()
                simultaneous_node.add_child(right)
            
            return simultaneous_node
        
        return left
    
    def parse_parallel(self) -> MSLNode:
        """ë³‘ë ¬ ì‹¤í–‰ íŒŒì‹± (|) - (W,A)|(S,D)"""
        left = self.parse_hold_chain()
        
        if self.match(TokenType.PARALLEL):
            parallel_node = ParallelNode(self._get_position())
            parallel_node.add_child(left)
            
            while self.match(TokenType.PARALLEL):
                self.advance()  # | ì†Œë¹„
                right = self.parse_hold_chain()
                parallel_node.add_child(right)
            
            return parallel_node
        
        return left
    
    def parse_hold_chain(self) -> MSLNode:
        """í™€ë“œ ì—°ê²° íŒŒì‹± (>) - W>A>S"""
        left = self.parse_continuous()
        
        if self.match(TokenType.HOLD_CHAIN):
            hold_chain_node = HoldChainNode(self._get_position())
            hold_chain_node.add_child(left)
            
            while self.match(TokenType.HOLD_CHAIN):
                self.advance()  # > ì†Œë¹„
                right = self.parse_continuous()
                hold_chain_node.add_child(right)
            
            return hold_chain_node
        
        return left
    
    def parse_continuous(self) -> MSLNode:
        """ì—°ì† ì…ë ¥ íŒŒì‹± (&) - Space&1000"""
        left = self.parse_repeat()
        
        if self.match(TokenType.CONTINUOUS):
            self.advance()  # & ì†Œë¹„
            
            # ì—°ì† ì‹œê°„ íŒŒì‹±
            if not self.match(TokenType.NUMBER):
                raise ParseError("ì—°ì† ì…ë ¥(&) ë’¤ì—ëŠ” ì‹œê°„(ìˆ«ì)ì´ ì™€ì•¼ í•©ë‹ˆë‹¤", self.current_token)
            
            duration_token = self.expect(TokenType.NUMBER)
            duration = float(duration_token.value)
            
            continuous_node = ContinuousNode(self._get_position())
            continuous_node.add_child(left)
            continuous_node.duration = duration
            
            return continuous_node
        
        return left
    
    def parse_repeat(self) -> MSLNode:
        """ë°˜ë³µ íŒŒì‹± (*) - W*5"""
        left = self.parse_toggle()
        
        if self.match(TokenType.REPEAT):
            self.advance()  # * ì†Œë¹„
            
            # ë°˜ë³µ íšŸìˆ˜ íŒŒì‹±
            if not self.match(TokenType.NUMBER):
                raise ParseError("ë°˜ë³µ(*) ë’¤ì—ëŠ” íšŸìˆ˜(ìˆ«ì)ê°€ ì™€ì•¼ í•©ë‹ˆë‹¤", self.current_token)
            
            count_token = self.expect(TokenType.NUMBER)
            count = int(float(count_token.value))  # ì†Œìˆ˜ì ë„ ì²˜ë¦¬í•˜ë˜ ì •ìˆ˜ë¡œ ë³€í™˜
            
            repeat_node = RepeatNode(self._get_position())
            repeat_node.add_child(left)
            repeat_node.count = count
            
            # ë°˜ë³µ ê°„ê²© íŒŒì‹± {ìˆ«ì}
            if self.match(TokenType.INTERVAL_START):
                self.advance()  # { ì†Œë¹„
                
                if not self.match(TokenType.NUMBER):
                    raise ParseError("ë°˜ë³µ ê°„ê²©({) ë’¤ì—ëŠ” ì‹œê°„(ìˆ«ì)ì´ ì™€ì•¼ í•©ë‹ˆë‹¤", self.current_token)
                
                interval_token = self.expect(TokenType.NUMBER)
                interval = float(interval_token.value)
                repeat_node.interval = interval
                
                self.expect(TokenType.INTERVAL_END)  # } ì†Œë¹„
            
            return repeat_node
        
        return left
    
    def parse_toggle(self) -> MSLNode:
        """í† ê¸€ íŒŒì‹± (~) - ~CapsLock"""
        if self.match(TokenType.TOGGLE):
            self.advance()  # ~ ì†Œë¹„
            
            base_node = self.parse_primary()
            
            toggle_node = ToggleNode(self._get_position())
            toggle_node.add_child(base_node)
            
            return toggle_node
        
        return self.parse_primary()
    
    def parse_primary(self) -> MSLNode:
        """ê¸°ë³¸ ìš”ì†Œ íŒŒì‹± - í‚¤, ìˆ«ì, ë³€ìˆ˜, ë§ˆìš°ìŠ¤, ê·¸ë£¹ ë“±"""
        if not self.current_token:
            raise ParseError("ì˜ˆìƒì¹˜ ëª»í•œ ìŠ¤í¬ë¦½íŠ¸ ë")
        
        # ê·¸ë£¹ ì²˜ë¦¬ (...)
        if self.match(TokenType.DELAY_START):
            return self.parse_group()
        
        # í‚¤ ë…¸ë“œ
        elif self.match(TokenType.KEY):
            key_token = self.expect(TokenType.KEY)
            key_node = KeyNode(self._get_position(key_token))
            key_node.key = key_token.value
            
            # íƒ€ì´ë° ìˆ˜ì •ì í™•ì¸
            return self.parse_timing_modifiers(key_node)
        
        # ë³€ìˆ˜ ë…¸ë“œ
        elif self.match(TokenType.VARIABLE):
            var_token = self.expect(TokenType.VARIABLE)
            var_node = VariableNode(self._get_position(var_token))
            var_node.name = var_token.value[1:]  # $ ì œê±°
            
            return var_node
        
        # ë§ˆìš°ìŠ¤ ì¢Œí‘œ ë…¸ë“œ
        elif self.match(TokenType.MOUSE_COORD):
            coord_token = self.expect(TokenType.MOUSE_COORD)
            
            # @(x,y) íŒŒì‹±
            coord_str = coord_token.value[2:-1]  # @( ì™€ ) ì œê±°
            x_str, y_str = coord_str.split(',')
            x = int(x_str.strip())
            y = int(y_str.strip())
            
            mouse_node = MouseNode(self._get_position(coord_token))
            mouse_node.x = x
            mouse_node.y = y
            
            return mouse_node
        
        # íœ  ë…¸ë“œ
        elif self.match(TokenType.WHEEL):
            wheel_token = self.expect(TokenType.WHEEL)
            
            # wheel+3 ë˜ëŠ” wheel-2 íŒŒì‹±
            wheel_str = wheel_token.value
            direction = 1 if '+' in wheel_str else -1
            amount_str = wheel_str.split('+' if '+' in wheel_str else '-')[1]
            amount = int(amount_str) if amount_str else 1
            
            wheel_node = WheelNode(self._get_position(wheel_token))
            wheel_node.direction = direction
            wheel_node.amount = amount
            
            return wheel_node
        
        # ìˆ«ì ë…¸ë“œ (ë‹¨ë…ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ê²½ìš°)
        elif self.match(TokenType.NUMBER):
            number_token = self.expect(TokenType.NUMBER)
            number_node = NumberNode(self._get_position(number_token))
            number_node.value = float(number_token.value)
            
            return number_node
        
        else:
            raise ParseError(f"ì˜ˆìƒì¹˜ ëª»í•œ í† í°: {self.current_token.value}", self.current_token)
    
    def parse_group(self) -> MSLNode:
        """ê·¸ë£¹ íŒŒì‹± (...) - ê´„í˜¸ë¡œ ë¬¶ì¸ í‘œí˜„ì‹"""
        self.expect(TokenType.DELAY_START)  # ( ì†Œë¹„
        
        # ê·¸ë£¹ ë‚´ë¶€ í‘œí˜„ì‹ íŒŒì‹±
        inner_expr = self.parse_expression()
        
        self.expect(TokenType.DELAY_END)  # ) ì†Œë¹„
        
        return inner_expr
    
    def parse_timing_modifiers(self, base_node: MSLNode) -> MSLNode:
        """íƒ€ì´ë° ìˆ˜ì •ì íŒŒì‹± - í‚¤ ë’¤ì— ì˜¤ëŠ” ì§€ì—°, í™€ë“œ ë“±"""
        result = base_node
        
        # ì§€ì—° ì‹œê°„ (ìˆ«ì) - W(500)
        if self.match(TokenType.DELAY_START):
            self.advance()  # ( ì†Œë¹„
            
            if not self.match(TokenType.NUMBER):
                raise ParseError("ì§€ì—° ì‹œê°„ ê´„í˜¸ ì•ˆì—ëŠ” ìˆ«ìê°€ ì™€ì•¼ í•©ë‹ˆë‹¤", self.current_token)
            
            delay_token = self.expect(TokenType.NUMBER)
            delay = float(delay_token.value)
            
            self.expect(TokenType.DELAY_END)  # ) ì†Œë¹„
            
            delay_node = DelayNode(self._get_position())
            delay_node.add_child(result)
            delay_node.duration = delay
            result = delay_node
        
        # í™€ë“œ ì‹œê°„ [ìˆ«ì] - W[1000]
        if self.match(TokenType.HOLD_START):
            self.advance()  # [ ì†Œë¹„
            
            if not self.match(TokenType.NUMBER):
                raise ParseError("í™€ë“œ ì‹œê°„ ê´„í˜¸ ì•ˆì—ëŠ” ìˆ«ìê°€ ì™€ì•¼ í•©ë‹ˆë‹¤", self.current_token)
            
            hold_token = self.expect(TokenType.NUMBER)
            hold_duration = float(hold_token.value)
            
            self.expect(TokenType.HOLD_END)  # ] ì†Œë¹„
            
            hold_node = HoldNode(self._get_position())
            hold_node.add_child(result)
            hold_node.duration = hold_duration
            result = hold_node
        
        # í˜ì´ë“œ ì‹œê°„ <ìˆ«ì> - W<500>
        if self.match(TokenType.FADE_START):
            self.advance()  # < ì†Œë¹„
            
            if not self.match(TokenType.NUMBER):
                raise ParseError("í˜ì´ë“œ ì‹œê°„ ê´„í˜¸ ì•ˆì—ëŠ” ìˆ«ìê°€ ì™€ì•¼ í•©ë‹ˆë‹¤", self.current_token)
            
            fade_token = self.expect(TokenType.NUMBER)
            fade_duration = float(fade_token.value)
            
            # fade endëŠ” '>' ì¸ë° ì´ë¯¸ HOLD_CHAINìœ¼ë¡œ ì‚¬ìš©ë˜ë¯€ë¡œ íŠ¹ë³„ ì²˜ë¦¬
            # ì‹¤ì œë¡œëŠ” êµ¬ë¬¸ ë¶„ì„ì—ì„œ ì²˜ë¦¬ê°€ ë³µì¡í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¼ë‹¨ ê°„ë‹¨íˆ ì²˜ë¦¬
            
            fade_node = FadeNode(self._get_position())
            fade_node.add_child(result)
            fade_node.duration = fade_duration
            result = fade_node
        
        return result
    
    def _get_position(self, token: Optional[Token] = None) -> Position:
        """í˜„ì¬ ìœ„ì¹˜ ì •ë³´ ìƒì„±"""
        if token:
            return Position(token.line, token.column)
        elif self.current_token:
            return Position(self.current_token.line, self.current_token.column)
        else:
            return Position(1, 1)
    
    def analyze_syntax(self, text: str) -> Dict[str, any]:
        """
        MSL ìŠ¤í¬ë¦½íŠ¸ì˜ êµ¬ë¬¸ì„ ë¶„ì„í•˜ì—¬ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            text (str): MSL ìŠ¤í¬ë¦½íŠ¸
            
        Returns:
            Dict: ë¶„ì„ ê²°ê³¼ (AST, ì˜¤ë¥˜, í†µê³„ ë“±)
        """
        try:
            ast = self.parse(text)
            
            return {
                'success': True,
                'ast': ast,
                'errors': [],
                'warnings': [],
                'statistics': self._analyze_ast_statistics(ast)
            }
        
        except ParseError as e:
            return {
                'success': False,
                'ast': None,
                'errors': [str(e)],
                'warnings': [],
                'statistics': {}
            }
    
    def _analyze_ast_statistics(self, ast: MSLNode) -> Dict[str, int]:
        """AST í†µê³„ ë¶„ì„"""
        stats = {
            'total_nodes': 0,
            'key_nodes': 0,
            'timing_nodes': 0,
            'operator_nodes': 0,
            'max_depth': 0
        }
        
        def count_nodes(node: MSLNode, depth: int = 0):
            stats['total_nodes'] += 1
            stats['max_depth'] = max(stats['max_depth'], depth)
            
            if isinstance(node, KeyNode):
                stats['key_nodes'] += 1
            elif isinstance(node, (DelayNode, HoldNode, FadeNode)):
                stats['timing_nodes'] += 1
            elif isinstance(node, (SequentialNode, SimultaneousNode, ParallelNode)):
                stats['operator_nodes'] += 1
            
            for child in node.children:
                count_nodes(child, depth + 1)
        
        count_nodes(ast)
        return stats


def demo_parser():
    """MSL Parser ë°ëª¨ í•¨ìˆ˜ - ë‹¤ì–‘í•œ MSL ìŠ¤í¬ë¦½íŠ¸ íŒŒì‹± ì˜ˆì œ"""
    parser = MSLParser()
    
    demo_scripts = [
        # ê¸°ë³¸ íŒŒì‹± í…ŒìŠ¤íŠ¸
        ("ê¸°ë³¸ í‚¤", "W"),
        ("ìˆœì°¨ ì‹¤í–‰", "W,A,S,D"),
        ("ë™ì‹œ ì‹¤í–‰", "Ctrl+C"),
        ("ì§€ì—° ì‹œê°„", "W(500)"),
        ("í™€ë“œ ì‹œê°„", "W[1000]"),
        ("ë°˜ë³µ", "W*5"),
        ("ì—°ì† ì…ë ¥", "Space&2000"),
        ("í† ê¸€", "~CapsLock"),
        
        # ë³µí•© íŒŒì‹± í…ŒìŠ¤íŠ¸
        ("ê²Œì„ ì½¤ë³´", "Q(100)W(150)E(200)R"),
        ("ë³µí•© ë§¤í¬ë¡œ", "Shift[2000]+(W,A,S,D)"),
        ("ë§ˆìš°ìŠ¤ ì œì–´", "@(100,200)"),
        ("íœ  ì œì–´", "wheel+3"),
        ("ë³€ìˆ˜ ì‚¬ìš©", "$combo1"),
        
        # ë³µì¡í•œ êµ¬ì¡°
        ("í™€ë“œ ì²´ì¸", "W>A>S>D"),
        ("ë³‘ë ¬ ì‹¤í–‰", "(W,A)|(S,D)"),
        ("ë°˜ë³µ ê°„ê²©", "W*5{200}"),
        
        # ì˜¤ë¥˜ í…ŒìŠ¤íŠ¸
        ("ì˜ëª»ëœ êµ¬ë¬¸", "W("),
        ("ë¹ˆ ìŠ¤í¬ë¦½íŠ¸", ""),
    ]
    
    print("=== MSL Parser ë°ëª¨ ===")
    print("MSL ìŠ¤í¬ë¦½íŠ¸ë¥¼ êµ¬ë¬¸ íŠ¸ë¦¬ë¡œ ë³€í™˜í•˜ëŠ” ì˜ˆì œ\n")
    
    for name, script in demo_scripts:
        print(f"ğŸ“ {name}: {script}")
        
        try:
            result = parser.analyze_syntax(script)
            
            if result['success']:
                print("   âœ… íŒŒì‹± ì„±ê³µ")
                print(f"   ğŸ“Š í†µê³„: {result['statistics']}")
                print(f"   ğŸŒ³ AST ë£¨íŠ¸: {type(result['ast']).__name__}")
            else:
                print("   âŒ íŒŒì‹± ì‹¤íŒ¨")
                for error in result['errors']:
                    print(f"      ì˜¤ë¥˜: {error}")
        
        except Exception as e:
            print(f"   ğŸ’¥ ì˜ˆì™¸ ë°œìƒ: {e}")
        
        print()


if __name__ == "__main__":
    demo_parser() 