using System;
using System.Collections.Generic;
using System.Threading.Tasks;
using SocketIOClient;
using NAudio.Wave;
using VoiceMacroPro.Models;
using System.Text.Json;
using System.IO;
using System.Linq;

namespace VoiceMacroPro.Services
{
    /// <summary>
    /// GPT-4o ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ì„ ìœ„í•œ WebSocket ê¸°ë°˜ ë˜í¼ ì„œë¹„ìŠ¤
    /// NAudioë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìº¡ì²˜ì™€ SocketIOë¥¼ í†µí•œ ì‹¤ì‹œê°„ í†µì‹ ì„ ì œê³µí•©ë‹ˆë‹¤.
    /// </summary>
    public class VoiceRecognitionWrapperService : IDisposable
    {
        private SocketIO? _socket;
        private WaveIn? _waveIn;
        private bool _isRecording = false;
        private bool _isInitialized = false;
        private readonly string _serverUrl;
        private readonly LoggingService _loggingService;
        private readonly AudioCaptureSettings _audioSettings;
        private VoiceSession _currentSession;
        private readonly List<TranscriptionResult> _sessionHistory;
        private readonly object _lock = new();
        private bool _isDisposed;

        // ë³¼ë¥¨ ì¦í­ ë° AGC ê´€ë ¨ í•„ë“œ
        private double _currentGainLevel = 1.0;
        private readonly Queue<double> _recentAudioLevels = new();
        private const int AGC_HISTORY_SIZE = 50; // AGC ê³„ì‚°ì„ ìœ„í•œ ìµœê·¼ ì˜¤ë””ì˜¤ ë ˆë²¨ ê¸°ë¡ ìˆ˜

        #region ì´ë²¤íŠ¸ ì •ì˜
        /// <summary>
        /// íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ë¥¼ ë°›ì„ ë•Œ ë°œìƒí•˜ëŠ” ì´ë²¤íŠ¸
        /// </summary>
        public event EventHandler<TranscriptionResult>? TranscriptionReceived;

        /// <summary>
        /// ì—ëŸ¬ ë°œìƒ ì‹œ ë°œìƒí•˜ëŠ” ì´ë²¤íŠ¸
        /// </summary>
        public event EventHandler<string>? ErrorOccurred;

        /// <summary>
        /// ì—°ê²° ìƒíƒœ ë³€ê²½ ì‹œ ë°œìƒí•˜ëŠ” ì´ë²¤íŠ¸
        /// </summary>
        public event EventHandler<ConnectionStatus>? ConnectionChanged;

        /// <summary>
        /// ë§¤í¬ë¡œ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°›ì„ ë•Œ ë°œìƒí•˜ëŠ” ì´ë²¤íŠ¸
        /// </summary>
        public event EventHandler<VoiceMatchResultModel>? MacroExecuted;

        /// <summary>
        /// ì˜¤ë””ì˜¤ ë ˆë²¨ ë³€ê²½ ì‹œ ë°œìƒí•˜ëŠ” ì´ë²¤íŠ¸ (ìŒì„± ì…ë ¥ ì‹œê°í™”ìš©)
        /// </summary>
        public event EventHandler<double>? AudioLevelChanged;
        #endregion

        /// <summary>
        /// VoiceRecognitionWrapperService ìƒì„±ì
        /// </summary>
        /// <param name="serverUrl">WebSocket ì„œë²„ URL (ê¸°ë³¸ê°’: http://localhost:5000)</param>
        public VoiceRecognitionWrapperService(string serverUrl = "http://localhost:5000")
        {
            _serverUrl = serverUrl;
            _loggingService = LoggingService.Instance;
            _audioSettings = new AudioCaptureSettings(); // GPT-4o ìµœì í™” ì„¤ì •
            
            // ì˜¤ë””ì˜¤ ì„¤ì • ê²€ì¦ ë° ì¡°ì •
            _audioSettings.ValidateAndAdjustAmplificationSettings();
            
            _sessionHistory = new List<TranscriptionResult>();
            _currentSession = new VoiceSession();
            InitializeAudioCapture();
        }

        /// <summary>
        /// ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜
        /// WebSocket ì—°ê²°, ì˜¤ë””ì˜¤ ìº¡ì²˜ ì„¤ì •, ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        /// </summary>
        /// <returns>ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€</returns>
        public async Task<bool> InitializeAsync()
        {
            try
            {
                _loggingService.LogInfo("GPT-4o ìŒì„±ì¸ì‹ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹œì‘");

                // WebSocket í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
                _socket = new SocketIO(_serverUrl);

                // WebSocket ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ë“±ë¡
                SetupSocketEventHandlers();

                // WebSocket ì„œë²„ì— ì—°ê²°
                await _socket.ConnectAsync();
                _loggingService.LogInfo("WebSocket ì„œë²„ ì—°ê²° ì„±ê³µ");

                // ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì´ˆê¸°í™”
                InitializeAudioCapture();
                _loggingService.LogInfo("ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ");

                // ìƒˆ ì„¸ì…˜ ìƒì„±
                _currentSession = new VoiceSession
                {
                    SessionId = Guid.NewGuid().ToString(),
                    StartTime = DateTime.Now
                };

                _isInitialized = true;
                
                // ì—°ê²° ìƒíƒœ ì´ë²¤íŠ¸ ë°œìƒ
                ConnectionChanged?.Invoke(this, ConnectionStatus.Connected);

                _loggingService.LogInfo("GPT-4o ìŒì„±ì¸ì‹ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ");
                return true;
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"ìŒì„±ì¸ì‹ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {ex.Message}");
                ErrorOccurred?.Invoke(this, $"ì´ˆê¸°í™” ì‹¤íŒ¨: {ex.Message}");
                return false;
            }
        }

        /// <summary>
        /// WebSocket ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë“¤ì„ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜
        /// ê°ì¢… ì„œë²„ ì‘ë‹µ ì´ë²¤íŠ¸ì— ëŒ€í•œ ì²˜ë¦¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
        /// </summary>
        private void SetupSocketEventHandlers()
        {
            // ì—°ê²° í™•ì¸ ì´ë²¤íŠ¸ ìˆ˜ì‹ 
            _socket.OnConnected += (sender, e) =>
            {
                _loggingService.LogInfo("âœ… Socket.IO ì„œë²„ì— ì—°ê²°ë¨");
                ConnectionChanged?.Invoke(this, ConnectionStatus.Connected);
            };

            // ì„œë²„ ì—°ê²° í•´ì œ ì´ë²¤íŠ¸
            _socket.OnDisconnected += (sender, e) =>
            {
                _loggingService.LogWarning("âŒ Socket.IO ì„œë²„ ì—°ê²° í•´ì œë¨");
                ConnectionChanged?.Invoke(this, ConnectionStatus.Disconnected);
            };

            // ì—°ê²° ì˜¤ë¥˜ ì´ë²¤íŠ¸
            _socket.OnError += (sender, e) =>
            {
                _loggingService.LogError($"âŒ Socket.IO ì—°ê²° ì˜¤ë¥˜: {e}");
                ErrorOccurred?.Invoke(this, $"ì—°ê²° ì˜¤ë¥˜: {e}");
            };

            // íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ìˆ˜ì‹ 
            _socket.On("transcription_result", response =>
            {
                try
                {
                    var result = response.GetValue<TranscriptionResult>();
                    TranscriptionReceived?.Invoke(this, result);
                }
                catch (Exception ex)
                {
                    ErrorOccurred?.Invoke(this, $"íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {ex.Message}");
                }
            });

            // ë§¤í¬ë¡œ ì‹¤í–‰ ê²°ê³¼ ìˆ˜ì‹ 
            _socket.On("macro_executed", response =>
            {
                try
                {
                    var result = response.GetValue<VoiceMatchResultModel>();
                    MacroExecuted?.Invoke(this, result);
                }
                catch (Exception ex)
                {
                    ErrorOccurred?.Invoke(this, $"ë§¤í¬ë¡œ ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {ex.Message}");
                }
            });

            // ìŒì„±ì¸ì‹ ìƒíƒœ ì´ë²¤íŠ¸ë“¤
            _socket.On("voice_recognition_started", HandleVoiceRecognitionStarted);
            _socket.On("voice_recognition_stopped", HandleVoiceRecognitionStopped);
            _socket.On("voice_recognition_error", HandleVoiceRecognitionError);

            // ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì´ë²¤íŠ¸ë“¤
            _socket.On("audio_chunk_received", HandleAudioChunkReceived);
            _socket.On("audio_processing_error", HandleAudioProcessingError);
            _socket.On("transcription_error", HandleTranscriptionError);
        }

        /// <summary>
        /// ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìº¡ì²˜ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜
        /// ìœˆë„ìš° ê¸°ë³¸ ë§ˆì´í¬ë¥¼ ìë™ ê°ì§€í•˜ì—¬ GPT-4oì— ìµœì í™”ëœ ì˜¤ë””ì˜¤ ì„¤ì •ì„ ì ìš©í•©ë‹ˆë‹¤.
        /// </summary>
        private void InitializeAudioCapture()
        {
            try
            {
                // ìœˆë„ìš° ê¸°ë³¸ ë§ˆì´í¬ ì¥ì¹˜ ì •ë³´ ë¡œê¹…
                LogAvailableAudioDevices();

                _waveIn = new WaveIn
                {
                    WaveFormat = new WaveFormat(16000, 1)
                };
                
                // ìœˆë„ìš° ê¸°ë³¸ ë§ˆì´í¬ ì¥ì¹˜ ì„¤ì • (DeviceNumber -1ì€ ì‹œìŠ¤í…œ ê¸°ë³¸ ì¥ì¹˜)
                _waveIn.DeviceNumber = -1;  // ìœˆë„ìš° ê¸°ë³¸ ë§ˆì´í¬ ì‚¬ìš©
                
                // GPT-4o ìµœì í™” ì˜¤ë””ì˜¤ ì„¤ì •: 24000Hz (24kHz) ìƒ˜í”Œë§ ë ˆì´íŠ¸
                _waveIn.WaveFormat = new WaveFormat(
                    24000,     // 24kHz ìƒ˜í”Œë§ ë ˆì´íŠ¸ (GPT-4o ìµœì í™”)
                    _audioSettings.BitsPerSample,  // 16ë¹„íŠ¸ ê¹Šì´
                    _audioSettings.Channels        // ëª¨ë…¸ (1ì±„ë„)
                );
                
                // ì‹¤ì‹œê°„ ì²˜ë¦¬ë¥¼ ìœ„í•œ 100ms ë²„í¼
                _waveIn.BufferMilliseconds = _audioSettings.BufferMilliseconds;

                // ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹  ì´ë²¤íŠ¸ ë“±ë¡
                _waveIn.DataAvailable += OnAudioDataAvailable;
                
                // ë…¹ìŒ ì¤‘ì§€ ì´ë²¤íŠ¸ ë“±ë¡
                _waveIn.RecordingStopped += OnRecordingStopped;

                // í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ë§ˆì´í¬ ì¥ì¹˜ ì •ë³´ ë¡œê¹…
                string deviceInfo = GetCurrentAudioDeviceInfo();
                _loggingService.LogInfo($"âœ… ì˜¤ë””ì˜¤ ìº¡ì²˜ ì„¤ì • ì™„ë£Œ: {deviceInfo}");
                _loggingService.LogInfo($"ğŸµ ì˜¤ë””ì˜¤ í˜•ì‹: 24000Hz, {_audioSettings.BitsPerSample}bit, {_audioSettings.Channels}ch, {_audioSettings.BufferMilliseconds}ms ë²„í¼");
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"âŒ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {ex.Message}");
                throw;
            }
        }

        /// <summary>
        /// ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ì…ë ¥ ì¥ì¹˜ ëª©ë¡ì„ ë¡œê¹…í•˜ëŠ” í•¨ìˆ˜
        /// ìœˆë„ìš°ì—ì„œ ì¸ì‹ë˜ëŠ” ëª¨ë“  ë§ˆì´í¬ ì¥ì¹˜ë¥¼ í™•ì¸í•˜ì—¬ ë””ë²„ê¹…ì— ë„ì›€ì„ ì¤ë‹ˆë‹¤.
        /// </summary>
        private void LogAvailableAudioDevices()
        {
            try
            {
                int deviceCount = WaveInEvent.DeviceCount;
                _loggingService.LogInfo($"ğŸ¤ ê°ì§€ëœ ì˜¤ë””ì˜¤ ì…ë ¥ ì¥ì¹˜ ìˆ˜: {deviceCount}ê°œ");

                if (deviceCount == 0)
                {
                    _loggingService.LogWarning("âš ï¸ ì˜¤ë””ì˜¤ ì…ë ¥ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.");
                    return;
                }

                // ê° ì¥ì¹˜ ì •ë³´ ì¶œë ¥
                for (int i = 0; i < deviceCount; i++)
                {
                    var capabilities = WaveInEvent.GetCapabilities(i);
                    _loggingService.LogInfo($"ğŸ“± ì¥ì¹˜ {i}: {capabilities.ProductName} (ì±„ë„: {capabilities.Channels})");
                }

                // ì‹œìŠ¤í…œ ê¸°ë³¸ ì¥ì¹˜ ì •ë³´
                _loggingService.LogInfo("ğŸ”§ ìœˆë„ìš° ê¸°ë³¸ ë§ˆì´í¬ ì¥ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. (DeviceNumber: -1)");
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"âŒ ì˜¤ë””ì˜¤ ì¥ì¹˜ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {ex.Message}");
            }
        }

        /// <summary>
        /// í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì˜¤ë””ì˜¤ ì¥ì¹˜ ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
        /// </summary>
        /// <returns>ì˜¤ë””ì˜¤ ì¥ì¹˜ ì •ë³´ ë¬¸ìì—´</returns>
        private string GetCurrentAudioDeviceInfo()
        {
            try
            {
                if (_waveIn.DeviceNumber == -1)
                {
                    return "ìœˆë„ìš° ì‹œìŠ¤í…œ ê¸°ë³¸ ë§ˆì´í¬ (ìë™ ì„ íƒ)";
                }
                else if (_waveIn.DeviceNumber >= 0 && _waveIn.DeviceNumber < WaveInEvent.DeviceCount)
                {
                    var capabilities = WaveInEvent.GetCapabilities(_waveIn.DeviceNumber);
                    return $"{capabilities.ProductName} (ì¥ì¹˜ ë²ˆí˜¸: {_waveIn.DeviceNumber})";
                }
                else
                {
                    return $"ì•Œ ìˆ˜ ì—†ëŠ” ì¥ì¹˜ (ì¥ì¹˜ ë²ˆí˜¸: {_waveIn.DeviceNumber})";
                }
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"âŒ ì¥ì¹˜ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {ex.Message}");
                return "ì¥ì¹˜ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨";
            }
        }

        /// <summary>
        /// ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬ ë° ì„œë²„ ì „ì†¡ í•¨ìˆ˜
        /// NAudioì—ì„œ ìº¡ì²˜ëœ ì˜¤ë””ì˜¤ë¥¼ Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ WebSocketìœ¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
        /// Voice Activity Detection (VAD) ë¡œì§ì„ í¬í•¨í•˜ì—¬ ì‹¤ì œ ìŒì„±ì´ ìˆì„ ë•Œë§Œ ì „ì†¡í•©ë‹ˆë‹¤.
        /// ë³¼ë¥¨ ì¦í­ ë° ìë™ ê²Œì¸ ì»¨íŠ¸ë¡¤ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.
        /// </summary>
        /// <param name="sender">ì´ë²¤íŠ¸ ë°œìƒì</param>
        /// <param name="e">ì˜¤ë””ì˜¤ ë°ì´í„° ì´ë²¤íŠ¸ ì¸ì</param>
        private async void OnAudioDataAvailable(object sender, WaveInEventArgs e)
        {
            if (_isRecording && _socket != null && _socket.Connected)
            {
                try
                {
                    // ì›ë³¸ ì˜¤ë””ì˜¤ ë ˆë²¨ ê³„ì‚°
                    double originalAudioLevel = CalculateAudioLevel(e.Buffer, e.BytesRecorded);
                    
                    // ë³¼ë¥¨ ì¦í­ ì²˜ë¦¬
                    byte[] processedBuffer = ProcessAudioWithAmplification(e.Buffer, e.BytesRecorded, originalAudioLevel);
                    
                    // ì¦í­ëœ ì˜¤ë””ì˜¤ ë ˆë²¨ ì¬ê³„ì‚°
                    double amplifiedAudioLevel = CalculateAudioLevel(processedBuffer, e.BytesRecorded);
                    
                    // UIìš© ì˜¤ë””ì˜¤ ë ˆë²¨ ì´ë²¤íŠ¸ ë°œìƒ (ì¦í­ëœ ë ˆë²¨ ì‚¬ìš©)
                    AudioLevelChanged?.Invoke(this, amplifiedAudioLevel);

                    // Voice Activity Detection (VAD) - ì¦í­ëœ ì˜¤ë””ì˜¤ ê¸°ì¤€ìœ¼ë¡œ í™•ì¸
                    bool hasVoiceActivity = IsVoiceActivityDetected(processedBuffer, e.BytesRecorded, amplifiedAudioLevel);
                    
                    if (hasVoiceActivity)
                    {
                        // ì¦í­ëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ Base64ë¡œ ì¸ì½”ë”©
                        string audioBase64 = Convert.ToBase64String(processedBuffer, 0, e.BytesRecorded);

                        // WebSocketì„ í†µí•´ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° (ìŒì„± ê°ì§€ì‹œë§Œ)
                        await _socket.EmitAsync("audio_chunk", new { 
                            audio = audioBase64,
                            audio_level = amplifiedAudioLevel,
                            original_level = originalAudioLevel,
                            gain_applied = _currentGainLevel,
                            has_voice = true 
                        });
                        
                        // ìŒì„± ê°ì§€ ë¡œê·¸ (ë””ë²„ê¹…ìš©)
                        _loggingService.LogDebug($"ğŸ¤ ìŒì„± ì „ì†¡ë¨ - ì›ë³¸: {originalAudioLevel:F3}, ì¦í­: {amplifiedAudioLevel:F3}, ê²Œì¸: {_currentGainLevel:F2}x");
                    }
                    else
                    {
                        // ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ì¹¨ë¬µ ë°ì´í„° ì „ì†¡í•˜ì§€ ì•ŠìŒ
                        _loggingService.LogDebug($"ğŸ”‡ ì¹¨ë¬µ ê°ì§€ë¨ (ì›ë³¸: {originalAudioLevel:F3}, ì¦í­: {amplifiedAudioLevel:F3}) - ì „ì†¡ ê±´ë„ˆëœ€");
                    }
                }
                catch (Exception ex)
                {
                    _loggingService.LogError($"ì˜¤ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜: {ex.Message}");
                    ErrorOccurred?.Invoke(this, $"ì˜¤ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜: {ex.Message}");
                }
            }
        }

        /// <summary>
        /// ì˜¤ë””ì˜¤ ë ˆë²¨ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (ìŒì„± ì…ë ¥ ì‹œê°í™”ìš©)
        /// </summary>
        /// <param name="buffer">ì˜¤ë””ì˜¤ ë²„í¼</param>
        /// <param name="bytesRecorded">ë…¹ìŒëœ ë°”ì´íŠ¸ ìˆ˜</param>
        /// <returns>ì •ê·œí™”ëœ ì˜¤ë””ì˜¤ ë ˆë²¨ (0.0 ~ 1.0)</returns>
        private double CalculateAudioLevel(byte[] buffer, int bytesRecorded)
        {
            double sum = 0;
            int samples = bytesRecorded / 2; // 16ë¹„íŠ¸ ìƒ˜í”Œ

            for (int i = 0; i < bytesRecorded; i += 2)
            {
                if (i + 1 < bytesRecorded)
                {
                    short sample = (short)((buffer[i + 1] << 8) | buffer[i]);
                    sum += Math.Abs(sample);
                }
            }

            double average = sum / samples;
            return Math.Min(1.0, average / 32768.0); // 0.0 ~ 1.0ìœ¼ë¡œ ì •ê·œí™”
        }

        /// <summary>
        /// Voice Activity Detection (VAD) - ì‹¤ì œ ìŒì„±ì´ ê°ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
        /// ë§ˆì´í¬ ì¡ìŒì´ë‚˜ ì¹¨ë¬µ ìƒíƒœì—ì„œëŠ” ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì „ì†¡í•˜ì§€ ì•Šê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
        /// </summary>
        /// <param name="buffer">ì˜¤ë””ì˜¤ ë²„í¼</param>
        /// <param name="bytesRecorded">ë…¹ìŒëœ ë°”ì´íŠ¸ ìˆ˜</param>
        /// <param name="audioLevel">ì´ë¯¸ ê³„ì‚°ëœ ì˜¤ë””ì˜¤ ë ˆë²¨</param>
        /// <returns>ìŒì„± í™œë™ì´ ê°ì§€ë˜ë©´ true, ì¹¨ë¬µì´ë‚˜ ì¡ìŒì´ë©´ false</returns>
        private bool IsVoiceActivityDetected(byte[] buffer, int bytesRecorded, double audioLevel)
        {
            // 1. ê¸°ë³¸ ë³¼ë¥¨ ì„ê³„ê°’ ì²´í¬ (ì¹¨ë¬µ í•„í„°ë§)
            const double MIN_VOLUME_THRESHOLD = 0.02; // 2% ì´ìƒì˜ ë³¼ë¥¨ í•„ìš”
            if (audioLevel < MIN_VOLUME_THRESHOLD)
            {
                return false; // ë„ˆë¬´ ì¡°ìš©í•˜ë©´ ì¹¨ë¬µìœ¼ë¡œ íŒë‹¨
            }

            // 2. ìµœëŒ€ ë³¼ë¥¨ ì„ê³„ê°’ ì²´í¬ (ê³¼ë„í•œ ì¡ìŒ í•„í„°ë§)
            const double MAX_VOLUME_THRESHOLD = 0.95; // 95% ì´ìƒì´ë©´ í´ë¦¬í•‘ìœ¼ë¡œ íŒë‹¨
            if (audioLevel > MAX_VOLUME_THRESHOLD)
            {
                return false; // ë„ˆë¬´ í¬ë©´ í´ë¦¬í•‘/ì¡ìŒìœ¼ë¡œ íŒë‹¨
            }

            // 3. ìŒì„± ì‹ í˜¸ì˜ ë™ì  ë²”ìœ„ í™•ì¸ (ìŒì„±ì€ ë³€í™”ê°€ ìˆì–´ì•¼ í•¨)
            bool hasVariation = CheckSignalVariation(buffer, bytesRecorded);
            if (!hasVariation)
            {
                return false; // ì¼ì •í•œ ì‹ í˜¸ëŠ” ì „ì ì¡ìŒìœ¼ë¡œ íŒë‹¨
            }

            // 4. ì œë¡œ í¬ë¡œì‹± ë¹„ìœ¨ í™•ì¸ (ìŒì„±ì€ ì ì ˆí•œ ì£¼íŒŒìˆ˜ ë³€í™”ë¥¼ ê°€ì§)
            double zeroCrossingRate = CalculateZeroCrossingRate(buffer, bytesRecorded);
            const double MIN_ZCR = 0.01; // ìµœì†Œ ì œë¡œ í¬ë¡œì‹± ë¹„ìœ¨
            const double MAX_ZCR = 0.30; // ìµœëŒ€ ì œë¡œ í¬ë¡œì‹± ë¹„ìœ¨
            if (zeroCrossingRate < MIN_ZCR || zeroCrossingRate > MAX_ZCR)
            {
                return false; // ì œë¡œ í¬ë¡œì‹±ì´ ë„ˆë¬´ ì ê±°ë‚˜ ë§ìœ¼ë©´ ì¡ìŒ
            }

            // ëª¨ë“  ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ ìŒì„±ìœ¼ë¡œ íŒë‹¨
            return true;
        }

        /// <summary>
        /// ì‹ í˜¸ì˜ ë³€í™”ëŸ‰ì„ í™•ì¸í•˜ì—¬ ì¼ì •í•œ ì¡ìŒì„ í•„í„°ë§í•˜ëŠ” í•¨ìˆ˜
        /// </summary>
        /// <param name="buffer">ì˜¤ë””ì˜¤ ë²„í¼</param>
        /// <param name="bytesRecorded">ë…¹ìŒëœ ë°”ì´íŠ¸ ìˆ˜</param>
        /// <returns>ì‹ í˜¸ì— ì¶©ë¶„í•œ ë³€í™”ê°€ ìˆìœ¼ë©´ true</returns>
        private bool CheckSignalVariation(byte[] buffer, int bytesRecorded)
        {
            if (bytesRecorded < 4) return false;

            double variance = 0;
            double mean = 0;
            int samples = bytesRecorded / 2;

            // í‰ê·  ê³„ì‚°
            for (int i = 0; i < bytesRecorded; i += 2)
            {
                if (i + 1 < bytesRecorded)
                {
                    short sample = (short)((buffer[i + 1] << 8) | buffer[i]);
                    mean += sample;
                }
            }
            mean /= samples;

            // ë¶„ì‚° ê³„ì‚°
            for (int i = 0; i < bytesRecorded; i += 2)
            {
                if (i + 1 < bytesRecorded)
                {
                    short sample = (short)((buffer[i + 1] << 8) | buffer[i]);
                    variance += Math.Pow(sample - mean, 2);
                }
            }
            variance /= samples;

            // í‘œì¤€í¸ì°¨ê°€ ì¼ì • ê°’ ì´ìƒì´ì–´ì•¼ ìŒì„±ìœ¼ë¡œ íŒë‹¨
            double standardDeviation = Math.Sqrt(variance);
            const double MIN_VARIATION = 100.0; // ìµœì†Œ ë³€í™”ëŸ‰ ì„ê³„ê°’
            
            return standardDeviation > MIN_VARIATION;
        }

        /// <summary>
        /// ì œë¡œ í¬ë¡œì‹± ë¹„ìœ¨ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (ìŒì„± ì‹ í˜¸ ë¶„ì„ìš©)
        /// </summary>
        /// <param name="buffer">ì˜¤ë””ì˜¤ ë²„í¼</param>
        /// <param name="bytesRecorded">ë…¹ìŒëœ ë°”ì´íŠ¸ ìˆ˜</param>
        /// <returns>ì œë¡œ í¬ë¡œì‹± ë¹„ìœ¨ (0.0 ~ 1.0)</returns>
        private double CalculateZeroCrossingRate(byte[] buffer, int bytesRecorded)
        {
            if (bytesRecorded < 4) return 0.0;

            int zeroCrossings = 0;
            int samples = bytesRecorded / 2;
            short previousSample = 0;

            for (int i = 0; i < bytesRecorded; i += 2)
            {
                if (i + 1 < bytesRecorded)
                {
                    short currentSample = (short)((buffer[i + 1] << 8) | buffer[i]);
                    
                    if (i > 0 && ((previousSample >= 0 && currentSample < 0) || (previousSample < 0 && currentSample >= 0)))
                    {
                        zeroCrossings++;
                    }
                    
                    previousSample = currentSample;
                }
            }

            return (double)zeroCrossings / samples;
        }

        /// <summary>
        /// ë³¼ë¥¨ ì¦í­ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë©”ì„œë“œ
        /// ìë™ ê²Œì¸ ì»¨íŠ¸ë¡¤, í´ë¦¬í•‘ ë°©ì§€, ë³¼ë¥¨ ì¦í­ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.
        /// </summary>
        /// <param name="inputBuffer">ì…ë ¥ ì˜¤ë””ì˜¤ ë²„í¼</param>
        /// <param name="bytesRecorded">ë…¹ìŒëœ ë°”ì´íŠ¸ ìˆ˜</param>
        /// <param name="currentAudioLevel">í˜„ì¬ ì˜¤ë””ì˜¤ ë ˆë²¨</param>
        /// <returns>ì¦í­ ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ë²„í¼</returns>
        private byte[] ProcessAudioWithAmplification(byte[] inputBuffer, int bytesRecorded, double currentAudioLevel)
        {
            // ë³¼ë¥¨ ì¦í­ì´ ë¹„í™œì„±í™”ëœ ê²½ìš° ì›ë³¸ ë²„í¼ ë°˜í™˜
            if (!_audioSettings.EnableVolumeAmplification)
            {
                return inputBuffer;
            }

            // ì¶œë ¥ ë²„í¼ ìƒì„± (ì›ë³¸ê³¼ ë™ì¼í•œ í¬ê¸°)
            byte[] outputBuffer = new byte[inputBuffer.Length];
            Array.Copy(inputBuffer, outputBuffer, bytesRecorded);

            try
            {
                // ìë™ ê²Œì¸ ì»¨íŠ¸ë¡¤ (AGC) ì²˜ë¦¬
                if (_audioSettings.EnableAutoGainControl)
                {
                    UpdateAutoGainControl(currentAudioLevel);
                }
                else
                {
                    // AGCê°€ ë¹„í™œì„±í™”ëœ ê²½ìš° ê³ ì • ì¦í­ ë°°ìœ¨ ì‚¬ìš©
                    _currentGainLevel = _audioSettings.VolumeAmplification;
                }

                // ì‹¤ì œ ë³¼ë¥¨ ì¦í­ ì ìš©
                ApplyVolumeAmplification(outputBuffer, bytesRecorded, _currentGainLevel);

                return outputBuffer;
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"ë³¼ë¥¨ ì¦í­ ì²˜ë¦¬ ì˜¤ë¥˜: {ex.Message}");
                // ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ë²„í¼ ë°˜í™˜
                return inputBuffer;
            }
        }

        /// <summary>
        /// ìë™ ê²Œì¸ ì»¨íŠ¸ë¡¤ (AGC)ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ë©”ì„œë“œ
        /// </summary>
        /// <param name="currentAudioLevel">í˜„ì¬ ì˜¤ë””ì˜¤ ë ˆë²¨</param>
        private void UpdateAutoGainControl(double currentAudioLevel)
        {
            // ìµœê·¼ ì˜¤ë””ì˜¤ ë ˆë²¨ ê¸°ë¡ì— ì¶”ê°€
            _recentAudioLevels.Enqueue(currentAudioLevel);
            
            // ê¸°ë¡ í¬ê¸° ì œí•œ
            while (_recentAudioLevels.Count > AGC_HISTORY_SIZE)
            {
                _recentAudioLevels.Dequeue();
            }

            // ì¶©ë¶„í•œ ê¸°ë¡ì´ ì—†ìœ¼ë©´ í˜„ì¬ ì„¤ì • ìœ ì§€
            if (_recentAudioLevels.Count < 10)
            {
                return;
            }

            // ìµœê·¼ í‰ê·  ì˜¤ë””ì˜¤ ë ˆë²¨ ê³„ì‚°
            double averageLevel = _recentAudioLevels.Average();
            
            // ëª©í‘œ ë ˆë²¨ê³¼ì˜ ì°¨ì´ ê³„ì‚°
            double targetLevel = _audioSettings.AutoGainTargetLevel;
            double levelDifference = targetLevel - averageLevel;

            // AGC ì¡°ì • (ë¶€ë“œëŸ¬ìš´ ì¡°ì •ì„ ìœ„í•´ ì‘ì€ ë‹¨ê³„ë¡œ)
            if (Math.Abs(levelDifference) > 0.1) // 10% ì´ìƒ ì°¨ì´ê°€ ë‚  ë•Œë§Œ ì¡°ì •
            {
                double adjustmentFactor = 1.0 + (levelDifference * 0.5); // 50% ë¹„ìœ¨ë¡œ ì¡°ì •
                
                // ìƒˆë¡œìš´ ê²Œì¸ ë ˆë²¨ ê³„ì‚°
                double newGainLevel = _currentGainLevel * adjustmentFactor;
                
                // ì•ˆì „í•œ ë²”ìœ„ë¡œ ì œí•œ (0.5x ~ 10x)
                newGainLevel = Math.Max(0.5, Math.Min(10.0, newGainLevel));
                
                // ë¶€ë“œëŸ¬ìš´ ì „í™˜ì„ ìœ„í•´ ì ì§„ì  ë³€ê²½ (10% ë‹¨ê³„)
                _currentGainLevel = _currentGainLevel * 0.9 + newGainLevel * 0.1;
                
                _loggingService.LogDebug($"ğŸ”§ AGC ì¡°ì •: í‰ê·  ë ˆë²¨ {averageLevel:F3} â†’ ëª©í‘œ {targetLevel:F3}, ê²Œì¸: {_currentGainLevel:F2}x");
            }
        }

        /// <summary>
        /// ì‹¤ì œ ë³¼ë¥¨ ì¦í­ì„ ì˜¤ë””ì˜¤ ë²„í¼ì— ì ìš©í•˜ëŠ” ë©”ì„œë“œ
        /// </summary>
        /// <param name="buffer">ì¦í­í•  ì˜¤ë””ì˜¤ ë²„í¼</param>
        /// <param name="bytesRecorded">ë…¹ìŒëœ ë°”ì´íŠ¸ ìˆ˜</param>
        /// <param name="gainLevel">ì ìš©í•  ê²Œì¸ ë ˆë²¨</param>
        private void ApplyVolumeAmplification(byte[] buffer, int bytesRecorded, double gainLevel)
        {
            // ê²Œì¸ì´ 1.0ì— ê°€ê¹Œìš°ë©´ ì¦í­ ìƒëµ (ì„±ëŠ¥ ìµœì í™”)
            if (Math.Abs(gainLevel - 1.0) < 0.01)
            {
                return;
            }

            // 16ë¹„íŠ¸ ìƒ˜í”Œ ì²˜ë¦¬
            for (int i = 0; i < bytesRecorded; i += 2)
            {
                if (i + 1 < bytesRecorded)
                {
                    // ë¦¬í‹€ ì—”ë””ì•ˆ 16ë¹„íŠ¸ ìƒ˜í”Œ ì½ê¸°
                    short sample = (short)((buffer[i + 1] << 8) | buffer[i]);
                    
                    // ê²Œì¸ ì ìš©
                    double amplifiedSample = sample * gainLevel;
                    
                    // í´ë¦¬í•‘ ë°©ì§€
                    if (_audioSettings.EnableClippingPrevention)
                    {
                        amplifiedSample = Math.Max(-32768, Math.Min(32767, amplifiedSample));
                    }
                    else
                    {
                        // í•˜ë“œ í´ë¦¬í•‘ (ì›ë³¸ ë™ì‘ ìœ ì§€)
                        amplifiedSample = Math.Max(-32768, Math.Min(32767, amplifiedSample));
                    }
                    
                    // ë‹¤ì‹œ 16ë¹„íŠ¸ë¡œ ë³€í™˜
                    short amplifiedShort = (short)Math.Round(amplifiedSample);
                    
                    // ë¦¬í‹€ ì—”ë””ì•ˆìœ¼ë¡œ ë²„í¼ì— ì €ì¥
                    buffer[i] = (byte)(amplifiedShort & 0xFF);
                    buffer[i + 1] = (byte)((amplifiedShort >> 8) & 0xFF);
                }
            }
        }

        /// <summary>
        /// í˜„ì¬ ë³¼ë¥¨ ì¦í­ ì„¤ì •ì„ ê°€ì ¸ì˜¤ëŠ” ë©”ì„œë“œ
        /// </summary>
        /// <returns>í˜„ì¬ ë³¼ë¥¨ ì¦í­ ì •ë³´</returns>
        public (double amplification, bool enabled, bool agcEnabled, double currentGain) GetVolumeAmplificationInfo()
        {
            return (
                _audioSettings.VolumeAmplification,
                _audioSettings.EnableVolumeAmplification,
                _audioSettings.EnableAutoGainControl,
                _currentGainLevel
            );
        }

        /// <summary>
        /// ë³¼ë¥¨ ì¦í­ ì„¤ì •ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ë©”ì„œë“œ
        /// </summary>
        /// <param name="amplification">ì¦í­ ë°°ìœ¨</param>
        /// <param name="enableAmplification">ì¦í­ í™œì„±í™” ì—¬ë¶€</param>
        /// <param name="enableAGC">ìë™ ê²Œì¸ ì»¨íŠ¸ë¡¤ í™œì„±í™” ì—¬ë¶€</param>
        public void UpdateVolumeAmplificationSettings(double amplification, bool enableAmplification, bool enableAGC = false)
        {
            _audioSettings.VolumeAmplification = amplification;
            _audioSettings.EnableVolumeAmplification = enableAmplification;
            _audioSettings.EnableAutoGainControl = enableAGC;
            
            // ì„¤ì • ê²€ì¦ ë° ì¡°ì •
            _audioSettings.ValidateAndAdjustAmplificationSettings();
            
            // AGCê°€ ë¹„í™œì„±í™”ë˜ë©´ í˜„ì¬ ê²Œì¸ì„ ê³ ì • ë°°ìœ¨ë¡œ ì¬ì„¤ì •
            if (!enableAGC)
            {
                _currentGainLevel = _audioSettings.VolumeAmplification;
                _recentAudioLevels.Clear(); // AGC ê¸°ë¡ ì´ˆê¸°í™”
            }
            
            _loggingService.LogInfo($"ğŸ”Š ë³¼ë¥¨ ì¦í­ ì„¤ì • ì—…ë°ì´íŠ¸: {amplification:F1}x, í™œì„±í™”: {enableAmplification}, AGC: {enableAGC}");
        }

        /// <summary>
        /// ìŒì„± ë…¹ìŒì„ ì‹œì‘í•˜ëŠ” í•¨ìˆ˜
        /// </summary>
        /// <returns>ë…¹ìŒ ì‹œì‘ ì„±ê³µ ì—¬ë¶€</returns>
        public async Task<bool> StartRecordingAsync()
        {
            if (!_isInitialized)
            {
                ErrorOccurred?.Invoke(this, "ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
                return false;
            }

            try
            {
                if (!_isRecording)
                {
                    _isRecording = true;
                    _waveIn.StartRecording();
                    
                    // ì„œë²„ì— ìŒì„±ì¸ì‹ ì‹œì‘ ì•Œë¦¼
                    await _socket.EmitAsync("start_voice_recognition");
                    
                    _loggingService.LogInfo("ìŒì„± ë…¹ìŒ ì‹œì‘");
                    return true;
                }
                return true;
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜: {ex.Message}");
                ErrorOccurred?.Invoke(this, $"ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: {ex.Message}");
                return false;
            }
        }

        /// <summary>
        /// ìŒì„± ë…¹ìŒì„ ì¤‘ì§€í•˜ëŠ” í•¨ìˆ˜
        /// </summary>
        /// <returns>ë…¹ìŒ ì¤‘ì§€ ì„±ê³µ ì—¬ë¶€</returns>
        public async Task<bool> StopRecordingAsync()
        {
            try
            {
                if (_isRecording)
                {
                    _isRecording = false;
                    _waveIn.StopRecording();
                    
                    // ì„œë²„ì— ìŒì„±ì¸ì‹ ì¤‘ì§€ ì•Œë¦¼
                    await _socket.EmitAsync("stop_voice_recognition");
                    
                    _loggingService.LogInfo("ìŒì„± ë…¹ìŒ ì¤‘ì§€");
                    return true;
                }
                return true;
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜: {ex.Message}");
                ErrorOccurred?.Invoke(this, $"ë…¹ìŒ ì¤‘ì§€ ì‹¤íŒ¨: {ex.Message}");
                return false;
            }
        }

        #region WebSocket ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë“¤

        /// <summary>
        /// ìŒì„±ì¸ì‹ ì‹œì‘ í™•ì¸ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        /// </summary>
        private void HandleVoiceRecognitionStarted(SocketIOResponse response)
        {
            try
            {
                var data = response.GetValue<VoiceRecognitionStatusData>();
                _loggingService.LogInfo($"ğŸ¤ ìŒì„±ì¸ì‹ ì‹œì‘ í™•ì¸: {data.message}");
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"ìŒì„±ì¸ì‹ ì‹œì‘ í™•ì¸ ì²˜ë¦¬ ì˜¤ë¥˜: {ex.Message}");
            }
        }

        /// <summary>
        /// ìŒì„±ì¸ì‹ ì¤‘ì§€ í™•ì¸ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        /// </summary>
        private void HandleVoiceRecognitionStopped(SocketIOResponse response)
        {
            try
            {
                var data = response.GetValue<VoiceRecognitionStatusData>();
                _loggingService.LogInfo($"ğŸ›‘ ìŒì„±ì¸ì‹ ì¤‘ì§€ í™•ì¸: {data.message}");
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"ìŒì„±ì¸ì‹ ì¤‘ì§€ í™•ì¸ ì²˜ë¦¬ ì˜¤ë¥˜: {ex.Message}");
            }
        }

        /// <summary>
        /// ìŒì„±ì¸ì‹ ì˜¤ë¥˜ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        /// </summary>
        private void HandleVoiceRecognitionError(SocketIOResponse response)
        {
            try
            {
                var data = response.GetValue<VoiceRecognitionErrorData>();
                _loggingService.LogError($"ğŸš¨ ìŒì„±ì¸ì‹ ì˜¤ë¥˜: {data.error}");
                ErrorOccurred?.Invoke(this, $"ìŒì„±ì¸ì‹ ì˜¤ë¥˜: {data.error}");
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"ìŒì„±ì¸ì‹ ì˜¤ë¥˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {ex.Message}");
            }
        }

        /// <summary>
        /// ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹  í™•ì¸ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        /// </summary>
        private void HandleAudioChunkReceived(SocketIOResponse response)
        {
            try
            {
                var data = response.GetValue<AudioChunkReceivedData>();
                // ë¡œê·¸ ìŠ¤íŒ¸ ë°©ì§€ë¥¼ ìœ„í•´ Debug ë ˆë²¨ë¡œ ì²˜ë¦¬
                // _loggingService.LogDebug($"ğŸµ ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹  í™•ì¸: {data.audio_length} bytes");
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹  í™•ì¸ ì²˜ë¦¬ ì˜¤ë¥˜: {ex.Message}");
            }
        }

        /// <summary>
        /// ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        /// </summary>
        private void HandleAudioProcessingError(SocketIOResponse response)
        {
            try
            {
                var data = response.GetValue<AudioProcessingErrorData>();
                _loggingService.LogError($"ğŸš¨ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {data.error}");
                ErrorOccurred?.Invoke(this, $"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {data.error}");
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜ í•¸ë“¤ëŸ¬ ì˜¤ë¥˜: {ex.Message}");
            }
        }

        /// <summary>
        /// íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì˜¤ë¥˜ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        /// </summary>
        private void HandleTranscriptionError(SocketIOResponse response)
        {
            try
            {
                var data = response.GetValue<TranscriptionErrorData>();
                _loggingService.LogError($"ğŸš¨ íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì˜¤ë¥˜: {data.error}");
                ErrorOccurred?.Invoke(this, $"íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì˜¤ë¥˜: {data.error}");
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"íŠ¸ëœìŠ¤í¬ë¦½ì…˜ ì˜¤ë¥˜ í•¸ë“¤ëŸ¬ ì˜¤ë¥˜: {ex.Message}");
            }
        }

        #endregion

        /// <summary>
        /// ë…¹ìŒ ì¤‘ì§€ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
        /// </summary>
        /// <param name="sender">ì´ë²¤íŠ¸ ë°œìƒì</param>
        /// <param name="e">ì¤‘ì§€ ì´ë²¤íŠ¸ ì¸ì</param>
        private void OnRecordingStopped(object sender, StoppedEventArgs e)
        {
            if (e.Exception != null)
            {
                _loggingService.LogError($"ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜: {e.Exception.Message}");
                ErrorOccurred?.Invoke(this, $"ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜: {e.Exception.Message}");
            }
        }

        /// <summary>
        /// í˜„ì¬ ì„¸ì…˜ì˜ í†µê³„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
        /// </summary>
        /// <returns>ìŒì„± ì¸ì‹ ì„¸ì…˜ ì •ë³´</returns>
        public VoiceSession GetCurrentSession()
        {
            if (_sessionHistory.Count > 0)
            {
                double totalConfidence = 0;
                foreach (var result in _sessionHistory)
                {
                    totalConfidence += result.Confidence;
                }
                _currentSession.AverageConfidence = totalConfidence / _sessionHistory.Count;
            }

            return _currentSession;
        }

        /// <summary>
        /// ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
        /// </summary>
        /// <returns>ì—°ê²° ìƒíƒœ</returns>
        public bool IsConnected => _socket?.Connected ?? false;

        /// <summary>
        /// ë…¹ìŒ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
        /// </summary>
        /// <returns>ë…¹ìŒ ìƒíƒœ</returns>
        public bool IsRecording => _isRecording;

        /// <summary>
        /// ì˜¤ë””ì˜¤ ì¥ì¹˜ë¥¼ ë‹¤ì‹œ ê°ì§€í•˜ê³  ì„¤ì •ì„ ìƒˆë¡œê³ ì¹¨í•˜ëŠ” í•¨ìˆ˜
        /// ë§ˆì´í¬ê°€ ë³€ê²½ë˜ê±°ë‚˜ ìƒˆë¡œ ì—°ê²°ë˜ì—ˆì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        /// </summary>
        public async Task<bool> RefreshAudioDeviceAsync()
        {
            try
            {
                _loggingService.LogInfo("ğŸ”„ ì˜¤ë””ì˜¤ ì¥ì¹˜ ìƒˆë¡œê³ ì¹¨ ì‹œì‘...");

                // í˜„ì¬ ë…¹ìŒ ì¤‘ì´ë©´ ì¤‘ì§€
                bool wasRecording = _isRecording;
                if (wasRecording)
                {
                    await StopRecordingAsync();
                }

                // ê¸°ì¡´ WaveIn í•´ì œ
                _waveIn?.Dispose();

                // ì˜¤ë””ì˜¤ ìº¡ì²˜ ì¬ì´ˆê¸°í™”
                InitializeAudioCapture();

                // ë…¹ìŒì´ ì§„í–‰ ì¤‘ì´ì—ˆë‹¤ë©´ ë‹¤ì‹œ ì‹œì‘
                if (wasRecording)
                {
                    await StartRecordingAsync();
                }

                _loggingService.LogInfo("âœ… ì˜¤ë””ì˜¤ ì¥ì¹˜ ìƒˆë¡œê³ ì¹¨ ì™„ë£Œ");
                return true;
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"âŒ ì˜¤ë””ì˜¤ ì¥ì¹˜ ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨: {ex.Message}");
                ErrorOccurred?.Invoke(this, $"ì˜¤ë””ì˜¤ ì¥ì¹˜ ìƒˆë¡œê³ ì¹¨ ì‹¤íŒ¨: {ex.Message}");
                return false;
            }
        }

        /// <summary>
        /// ë¦¬ì†ŒìŠ¤ë¥¼ í•´ì œí•˜ëŠ” í•¨ìˆ˜
        /// WebSocket ì—°ê²° í•´ì œ, ì˜¤ë””ì˜¤ ìº¡ì²˜ ì¤‘ì§€, ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì •ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        /// </summary>
        public void Dispose()
        {
            try
            {
                if (_isRecording)
                {
                    StopRecordingAsync().Wait(1000); // 1ì´ˆ ëŒ€ê¸°
                }

                _waveIn?.Dispose();
                _socket?.DisconnectAsync().Wait(1000); // 1ì´ˆ ëŒ€ê¸°
                _socket?.Dispose();

                _loggingService.LogInfo("VoiceRecognitionWrapperService ë¦¬ì†ŒìŠ¤ í•´ì œ ì™„ë£Œ");
            }
            catch (Exception ex)
            {
                _loggingService.LogError($"ë¦¬ì†ŒìŠ¤ í•´ì œ ì¤‘ ì˜¤ë¥˜: {ex.Message}");
            }
        }
    }
} 